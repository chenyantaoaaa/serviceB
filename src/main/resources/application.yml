#common config#
spring:
  application:
    name: serviceB
#  cloud:
#    config:
#      enabled: false
  rabbitmq:
    host: 112.74.160.172
    port: 5672
    username: test
    password: 123456
    publisher-confirms: true
    virtual-host: /
    listener:
      simple:
        acknowledge-mode: manual
  kafka:
    bootstrap-servers: 112.74.160.172:9092
    consumer:
      # 指定一个默认的组名
#      group-id: kafka2
      # earliest:当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，从头开始消费
      # latest:当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，消费新产生的该分区下的数据
      # none:topic各分区都存在已提交的offset时，从offset后开始消费；只要有一个分区不存在已提交的offset，则抛出异常
      auto-offset-reset: earliest
      # key/value的反序列化
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
    producer:
          # key/value的序列化
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      # 批量抓取
      batch-size: 65536
      # 缓存容量
      buffer-memory: 524288
      # 服务器地址
      bootstrap-servers: 112.74.160.172:9092
#  datasource:
#    type: com.alibaba.druid.pool.DruidDataSource
#    driver-class-name: com.mysql.jdbc.Driver
#    url: jdbc:mysql://112.74.160.172:3306/learn?useUnicode=true&characterEncoding=UTF-8
#    username: root
#    password: a86358201
  datasource:
    type: com.alibaba.druid.pool.DruidDataSource
    driver-class-name: com.mysql.jdbc.Driver
    url: jdbc:mysql://112.74.160.172:3306/learn?useUnicode=true&characterEncoding=UTF-8
    username: root
    password: a86358201

#网关端口#
server:
  port: 5013

#mybatis:
#  config-location: classpath:com.springcloud.com.springcloud.mapper/*.xml

#eureka:
#  instance:
#    hostname: localhost
#  client:
#    enabled: true
#    service-url:
#      defaultZone: http://127.0.0.1:8660/eureka/
